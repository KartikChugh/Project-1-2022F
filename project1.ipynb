{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "comparable-extent",
   "metadata": {},
   "source": [
    "# Project 1: Assembling Genes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-globe",
   "metadata": {},
   "source": [
    "   <div class=\"alert alert-block alert-danger\">\n",
    "    <center>Due: <b>Monday, September 5, 8:59pm</b>.</center> \n",
    "   </div>\n",
    "   \n",
    "   <div class=\"alert alert-block alert-warning\">\n",
    "   <center>\n",
    "       <b>Collaboration and Resource Policy</b>\n",
    "    </center>\n",
    "    \n",
    "For this assignment, you are encouraged to work with one other person satisfying the constraints from Class 2. \n",
    "You are permitted (actually _encouraged_) to discuss these problems with anyone you want, including other students in the class. If you do discuss the specific questions in the assignment with anyone other than your assignment partner and the course staff, though, you should list them in the _External resources used_ section below.\n",
    "    \n",
    "You are welcome to use any resources you want for this assignment, other than ones that would defeat the purpose of the assignment. This means you should not look at answers or code from previous semesters of this course, or from any other students in the class (other than your collaboration with your partner), and if you find code that implements the problem you are being asked to do for the assignment, you should not use that code. You should document all external resource you use that are not part of the course materials in the _External resources used_ section below.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-result",
   "metadata": {},
   "source": [
    "**Team submitting this assignment:**  \n",
    "<div class=\"alert alert-success\">\n",
    "    <b><em>list each member of your team here, including both your name and UVA computing id</em></b>\n",
    "\n",
    "Team Members (Names):  \n",
    "\n",
    "Team Member UVA Computing IDs:\n",
    "\n",
    "</div>\n",
    "\n",
    "**External resources used:** \n",
    "<div class=\"alert alert-success\">\n",
    "<em>It is not necessary to list the course materials, but if you used any other resources, including discussing problems with students not on your team, list them here.</em>\n",
    "    \n",
    "External Resources Used:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-bookmark",
   "metadata": {},
   "source": [
    "In this project, we will explore genome assemblyâ€”the process of determining the order of nucleotides in DNA from fragmented reads. As you might have studied in the reading assignments, genome assembly can get quite complicated, as problems such as full sequence coverage, finding a good length for reads (the $k$ in $k$-mer), and sequencing errors present challenges for sequencing analysis and accuracy. You can assume perfect coverage for all parts of the assignment and no read errors for the first two questions.\n",
    "\n",
    "\n",
    "<b>Submission</b>: Please submit the code you wrote to generate your answers for all parts using this form: <a href=\"https://forms.gle/rNTXfYojTLEQ8idg6\"><em>https://forms.gle/rNTXfYojTLEQ8idg6</em></a>. Your answers should be in the Jupyter Notebook, along with your code. Before submission, you should make a copy of your notebook file with the name <i>uvaid1\\_uvaid2.ipynb</i> (where <i>uvaidn</i> is each teammates UVA id) so the submitted file identifies you. You and your partner should submit a single file once together. Submission is due 8:59 pm (EST) on Monday, September 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-aaron",
   "metadata": {},
   "source": [
    "## Install basic required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-thesaurus",
   "metadata": {},
   "source": [
    "- Install basic required packages, should be run only once. You may need to restart the kernel after this stage.\n",
    "- Make sure you have [graphviz](https://graphviz.org/download/) installed on your system.\n",
    "- The second cell adds Graphviz to your path, you may have to change based on where the install folder is.\n",
    "\n",
    "<b>NOTE: We provide utils.py, which may contain helpful functions for you to use, as well as gvmagic.py, which is a deprecated package to use graphviz within the notebook</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "copyrighted-kingdom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\programdata\\miniconda\\lib\\site-packages (from -r requirements.txt (line 1)) (1.23.2)\n",
      "Requirement already satisfied: matplotlib in c:\\programdata\\miniconda\\lib\\site-packages (from -r requirements.txt (line 2)) (3.5.3)\n",
      "Requirement already satisfied: pydot in c:\\programdata\\miniconda\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: graphviz in c:\\programdata\\miniconda\\lib\\site-packages (from -r requirements.txt (line 4)) (0.20.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\miniconda\\lib\\site-packages (from matplotlib->-r requirements.txt (line 2)) (4.37.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 2)) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "great-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-realtor",
   "metadata": {},
   "source": [
    "## Genome Assembly\n",
    "\n",
    "For this part, you're given reads generated while trying to sequence the DNA of a TeleTubby (some unknown organism) with a \\textit{very} small genetic code. By answering the following questions, you will learn how to assemble the original genome sequence from sequence reads.\n",
    "\n",
    "Sequencing data is often stored in FASTQ file format. In TeleTubby.fastq, you will find the data organized in a particular order that repeats every four lines. The first line contains the metadata that encodes the name of the read, the experiment type, the kind of sequencing machine used, etc. The second line is the sequence of bases. The third line functions as a placeholder line. The fourth line is a sequence of base qualities that encode the qualities for the corresponding bases in the sequence line. We will only work with the sequence and quality score lines in this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accessible-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-vietnam",
   "metadata": {},
   "source": [
    "#### Question 1.1.1 GC-content\n",
    "\n",
    "The GC-content (or the ratio of G and C nucleotides) is related to the melting temperature of the DNA double helix. Use the following equation to calculate the melting temperature of DNA for TeleTubby $t_m$ in Celsius:\n",
    "\n",
    "\\begin{equation*}\n",
    "t_m = 64.9+0.41(\\%GC)-\\frac{500}{\\text{length of sequence}}\n",
    "\\end{equation*}\n",
    "\n",
    "As a reference, the human genome is known to have between 35%-60% GC-content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prescription-cartridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.34709897610922\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "# Read sequence reads (error-free) from file\n",
    "sequence_reads, qualities = utils.read_fastq('TeleTubby.fastq')\n",
    "\n",
    "# Calculate %GC content\n",
    "sequence_length = 0\n",
    "GC_content = 0\n",
    "for i in range(len(sequence_reads)):\n",
    "    sequence_length += len(sequence_reads[i])\n",
    "    for nucleotide in sequence_reads[i]:\n",
    "        if nucleotide == \"G\" or nucleotide == \"C\":\n",
    "            GC_content += 1\n",
    "GC_content = GC_content / sequence_length * 100 \n",
    "\n",
    "# Print out temperature in Celsius\n",
    "tm = 64.9 + 0.41*GC_content - 500/sequence_length\n",
    "print(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-doctrine",
   "metadata": {},
   "source": [
    "#### Question 1.1.2 Interpreting quality scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-pottery",
   "metadata": {},
   "source": [
    "Phred33 quality scores are represented as the character with an ASCII code equal to its value + 33 (to make them easy to print alongside genome sequences). List the top 5 most frequent scores in ASCII symbol as well as their Phredd33 scores in TeleTubby.fastq. You can refer to the [official Illumina website](https://support.illumina.com/help/BaseSpace_OLH_009008/Content/Source/Informatics/BS/QualityScoreEncoding_swBS.htm) to reference the scoring encoding.\n",
    "\n",
    "What is the average Phred33 score in TeleTubby.fastq?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "female-stand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Phred33 Score:\n",
      "34.476535836177476\n",
      "Top 5 Most Frequent Scores:\n",
      "5 20\n",
      "D 35\n",
      "F 37\n",
      "O 46\n",
      "< 27\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print average Phred33 score\n",
    "char_dictionary = {}\n",
    "\n",
    "sequence_reads, qualities = utils.read_fastq('TeleTubby.fastq')\n",
    "\n",
    "for i in range(len(qualities)):\n",
    "    for score in qualities[i]:\n",
    "        if score in char_dictionary:\n",
    "            char_dictionary[score][1] += 1\n",
    "        else:\n",
    "            char_dictionary[score] = [ord(score)-33, 1]\n",
    "\n",
    "# Average calculation\n",
    "sum_of_scores = 0\n",
    "num_of_scores = 0\n",
    "for char in char_dictionary.keys():\n",
    "    sum_of_scores += char_dictionary[char][0] * char_dictionary[char][1]\n",
    "    num_of_scores += char_dictionary[char][1]\n",
    "\n",
    "average = sum_of_scores / num_of_scores\n",
    "print(\"Average Phred33 Score:\")\n",
    "print(average)\n",
    "\n",
    "# Top 5 \n",
    "count = 0\n",
    "print(\"Top 5 Most Frequent Scores:\")\n",
    "while count < 5:\n",
    "    frequent = [\"\", 0, 0]\n",
    "    for char in char_dictionary.keys():\n",
    "        if char_dictionary[char][1] > frequent[1]:\n",
    "            frequent[0] = char\n",
    "            frequent[1] = char_dictionary[char][1]\n",
    "            frequent[2] = char_dictionary[char][0]\n",
    "            char_dictionary[char][1] = -1\n",
    "    print(frequent[0], frequent[2])\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-membrane",
   "metadata": {},
   "source": [
    "#### Question 1.1.3 Frequency analysis\n",
    "\n",
    "Looking at repetitions in the sequence can be helpful in estimating the \"redudancy\" in the organisms. Humand and other evolved animals have a lot of redundancy, while smaller organisms like bacteria have highly packed genomes. One heuristic to estimate this before actually performing the assembly could be looking at how often certain $k$-mers are repeated.\n",
    "\n",
    "<b>Print out the 3 most frequent k-mers with their frequencies</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "therapeutic-resolution",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GCTATCGC', 3]\n",
      "['TATCGCAA', 2]\n",
      "['CTATCGCA', 2]\n"
     ]
    }
   ],
   "source": [
    "# Find and print out the three most repeated k-mers and their frequencies\n",
    "sequence_reads, qualities = utils.read_fastq('TeleTubby.fastq')\n",
    "\n",
    "kmer_dict = {}\n",
    "\n",
    "for read in sequence_reads:\n",
    "    if read in kmer_dict:\n",
    "        kmer_dict[read] += 1\n",
    "    else:\n",
    "        kmer_dict[read] = 1\n",
    "        \n",
    "count = 0\n",
    "while count < 3:\n",
    "    frequent = [\"\", 0]\n",
    "    for kmer in kmer_dict.keys():\n",
    "        if kmer_dict[kmer] > frequent[1]:\n",
    "            frequent[0] = kmer\n",
    "            frequent[1] = kmer_dict[kmer]\n",
    "            kmer_dict[kmer] = -1\n",
    "    print(frequent)\n",
    "    count += 1     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-stocks",
   "metadata": {},
   "source": [
    "### Question 1.2. Greedy approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-topic",
   "metadata": {},
   "source": [
    "One of the approaches to assemble the genome from the given reads is a greedy algorithm. Have a look at the greedy algorithm described on [Wikipedia](https://en.wikipedia.org/wiki/Sequence_assembly#Greedy_algorithm) and answer the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-inclusion",
   "metadata": {},
   "source": [
    "#### Question 1.2.1 What would the runtime be of this algorithm, given $n$ $k$-mer reads?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-wrong",
   "metadata": {},
   "source": [
    "I quote the algorithm from Wikipedia as follows:\n",
    "1. Ð¡alculate pairwise alignments of all fragments.\n",
    "2. Choose two fragments with the largest overlap.\n",
    "3. Merge chosen fragments.\n",
    "4. Repeat step 2 and 3 until only one fragment is left.\n",
    "\n",
    "There is likely a small mistake in this writeup however. Step 1 may need to be repeated, since by merging two fragments we invalidate some of the overlap calculations performed in that step. I assume that Step 1 is repeated as well.\n",
    "\n",
    "As per the Handshake Theorem, forming a pairwise alignment between each fragment and all others would be an $n^2$ operation ($n$ fragments paired against $(n-1)$ counterparts, divided by 2 to account for duplication).\n",
    "\n",
    "Next we need to select the fragments that maximally overlap, which is a linear time search.\n",
    "\n",
    "For step three, we can remove the two such fragments and insert the merged one which is constant time e.g. set structure.\n",
    "\n",
    "The prior steps will repeat an additional $n-2$ times because we lose one fragment until we get to 1 supersequence. \n",
    "\n",
    "$(n^2 + n + 1) * (n-1) = O(n^3)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-title",
   "metadata": {},
   "source": [
    "#### Question 1.2.2 Would this algorithm always yield a unique solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-arrow",
   "metadata": {},
   "source": [
    "No, it would not. Consider an example where two alignments tie for the maximum overlap; one alignment is chosen to be merged arbitrarily, which may impact all future runs as they will consider that merged sequence as a new fragment to align with. \n",
    "\n",
    "Sequence: CGTTGCGTTA\n",
    "\n",
    "Fragments: CGTT, GTTA, GTTG, GCGT\n",
    "\n",
    "One execution where we start by merging the first and second fragment:\n",
    "1. CGTTA, GTTG, GCGT\n",
    "2. GCGTTA, GTTG\n",
    "3. GTTGCGTTA\n",
    "\n",
    "A different execution where we start by merging the first and fourth:\n",
    "1. GCGTT, GTTA, GTTG\n",
    "2. GCGTTG, GTTA\n",
    "3. GCGTTGTTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-backup",
   "metadata": {},
   "source": [
    "#### Question 1.2.3 Would this algorithm always yield the <i>right</i> solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-czech",
   "metadata": {},
   "source": [
    "No, it may reach a local optimum but not a global optimum with regards to sequence length. In fact, it may even discover a shorter supersequence of the fragments than the actual sequence, but still be incorrect as the sequence is plain different. An example:\n",
    "\n",
    "Sequence: CGTTGCGTTA\n",
    "\n",
    "Fragments: CGTT, GTTA, GTTG, GCGT\n",
    "If our execution starts by merging first and second instead of first and third:\n",
    "1. CGTTA, GTTG, GCGT\n",
    "2. GCGTTA, GTTG\n",
    "3. GTTGCGTTA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-peninsula",
   "metadata": {},
   "source": [
    "### Question 1.3 Graph-based approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-rebecca",
   "metadata": {},
   "source": [
    "Graphs for genome assembly can be constructed in two ways:\n",
    "\n",
    "- de Bruijn graph: Processing $k-$mers as edges, with $(k-1)-$mers as nodes, and\n",
    "- Overlap graph: Processing $k-$mers as nodes, with $(k-1)-$mers as edges.\n",
    "\n",
    "de Bruijn graphs can be processed to find Euler paths, while Overlap graphs can be processed to find Hamiltonian paths. Both of these are valid ways to reconstruct the original genome.\n",
    "\n",
    "<b>Use one of these two techniques to reconstruct the sequence, and print out your reconstructed sequence. Which method did you pick out of the two, and why? (hint: imagine what would happen when we have millions of reads). Use the k-mers provided in TeleTubby.fastq</b>.\n",
    "\n",
    "We provide some skeleton code that you may use, but you may also come up with your own solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "round-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reads into graph\n",
    "\n",
    "def build_graph(k_mers):\n",
    "    edges = []\n",
    "    nodes = set()\n",
    "    matrix = {}\n",
    "    outdegrees = {}\n",
    "    indegrees = {}\n",
    "    # Your code here\n",
    "    for sequence in k_mers:\n",
    "        edges.append(sequence)\n",
    "        prefix = sequence[:-1]\n",
    "        suffix = sequence[1:]\n",
    "        nodes.add(prefix)\n",
    "        nodes.add(suffix)\n",
    "\n",
    "        if prefix not in matrix:\n",
    "            matrix[prefix] = {}\n",
    "            outdegrees[prefix] = 0\n",
    "\n",
    "        if suffix not in indegrees:\n",
    "            indegrees[suffix] = 0\n",
    "\n",
    "        # Adds to adjacency matrix\n",
    "        matrix[prefix][suffix] = sequence\n",
    "        outdegrees[prefix] += 1\n",
    "        indegrees[suffix] += 1\n",
    "        \n",
    "            \n",
    "    return nodes, edges, matrix, outdegrees, indegrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8da75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges, matrix, outdegrees, indegrees = build_graph(sequence_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab3c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def endpoints(outdegrees, indegrees, nodes):\n",
    "    # Identify start node: outgoing edges is more than incoming\n",
    "    start = None\n",
    "    end = None\n",
    "\n",
    "    for subseq in nodes:\n",
    "        diff = outdegrees.get(subseq,0) - indegrees.get(subseq, 0)\n",
    "        if diff == 1:\n",
    "            start = subseq\n",
    "        elif diff == -1:\n",
    "            end = subseq\n",
    "\n",
    "    return start, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floral-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "start, end = endpoints(outdegrees, indegrees, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierholzer's algorithm\n",
    "\n",
    "def dfs_wrap(matrix, start):\n",
    "    visited = set()\n",
    "    path = []\n",
    "    path_nodes = []\n",
    "\n",
    "    def dfs(e, v):\n",
    "        v_edges = list(matrix.get(v, {}).values())\n",
    "        v_edges_unvisited = [_ for _ in v_edges if _ not in visited]\n",
    "        while (v_edges_unvisited):\n",
    "            edge = v_edges_unvisited.pop()\n",
    "            visited.add(edge)\n",
    "            v2 = edge[1:]\n",
    "            dfs(edge, v2)\n",
    "        \n",
    "        if e:\n",
    "            path.append(e)\n",
    "        path_nodes.append(v)\n",
    "\n",
    "    dfs(None, start)\n",
    "    return path, path_nodes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "032334d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edges:  288\n",
      "Nodes:  289\n",
      "Edges missing from path:  set()\n",
      "Nodes missing from path:  set()\n"
     ]
    }
   ],
   "source": [
    "path, path_nodes = dfs_wrap(matrix, start)\n",
    "\n",
    "print(\"Edges: \", len(path))\n",
    "print(\"Nodes: \", len(path_nodes))\n",
    "print(\"Edges missing from path: \", set(edges) ^ set(path)) # Should be empty\n",
    "print(\"Nodes missing from path: \", nodes ^ set(path_nodes)) # Should be empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2876de03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence of k mers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['TACGCCAA',\n",
       " 'ACGCCAAA',\n",
       " 'CGCCAAAT',\n",
       " 'GCCAAATA',\n",
       " 'CCAAATAG',\n",
       " 'CAAATAGC',\n",
       " 'AAATAGCA',\n",
       " 'AATAGCAA',\n",
       " 'ATAGCAAT',\n",
       " 'TAGCAATG',\n",
       " 'AGCAATGC',\n",
       " 'GCAATGCG',\n",
       " 'CAATGCGC',\n",
       " 'AATGCGCA',\n",
       " 'ATGCGCAG',\n",
       " 'TGCGCAGG',\n",
       " 'GCGCAGGA',\n",
       " 'CGCAGGAT',\n",
       " 'GCAGGATA',\n",
       " 'CAGGATAA',\n",
       " 'AGGATAAC',\n",
       " 'GGATAACA',\n",
       " 'GATAACAA',\n",
       " 'ATAACAAC',\n",
       " 'TAACAACT',\n",
       " 'AACAACTT',\n",
       " 'ACAACTTA',\n",
       " 'CAACTTAT',\n",
       " 'AACTTATG',\n",
       " 'ACTTATGT',\n",
       " 'CTTATGTA',\n",
       " 'TTATGTAC',\n",
       " 'TATGTACT',\n",
       " 'ATGTACTA',\n",
       " 'TGTACTAC',\n",
       " 'GTACTACA',\n",
       " 'TACTACAT',\n",
       " 'ACTACATG',\n",
       " 'CTACATGT',\n",
       " 'TACATGTT',\n",
       " 'ACATGTTG',\n",
       " 'CATGTTGT',\n",
       " 'ATGTTGTT',\n",
       " 'TGTTGTTT',\n",
       " 'GTTGTTTC',\n",
       " 'TTGTTTCT',\n",
       " 'TGTTTCTC',\n",
       " 'GTTTCTCG',\n",
       " 'TTTCTCGT',\n",
       " 'TTCTCGTG',\n",
       " 'TCTCGTGC',\n",
       " 'CTCGTGCC',\n",
       " 'TCGTGCCC',\n",
       " 'CGTGCCCG',\n",
       " 'GTGCCCGC',\n",
       " 'TGCCCGCC',\n",
       " 'GCCCGCCA',\n",
       " 'CCCGCCAA',\n",
       " 'CCGCCAAT',\n",
       " 'CGCCAATG',\n",
       " 'GCCAATGT',\n",
       " 'CCAATGTC',\n",
       " 'CAATGTCG',\n",
       " 'AATGTCGA',\n",
       " 'ATGTCGAG',\n",
       " 'TGTCGAGA',\n",
       " 'GTCGAGAG',\n",
       " 'TCGAGAGA',\n",
       " 'CGAGAGAT',\n",
       " 'GAGAGATT',\n",
       " 'AGAGATTT',\n",
       " 'GAGATTTG',\n",
       " 'AGATTTGT',\n",
       " 'GATTTGTG',\n",
       " 'ATTTGTGC',\n",
       " 'TTTGTGCT',\n",
       " 'TTGTGCTA',\n",
       " 'TGTGCTAT',\n",
       " 'GTGCTATC',\n",
       " 'TGCTATCG',\n",
       " 'GCTATCGC',\n",
       " 'CTATCGCA',\n",
       " 'TATCGCAA',\n",
       " 'ATCGCAAC',\n",
       " 'TCGCAACC',\n",
       " 'CGCAACCT',\n",
       " 'GCAACCTA',\n",
       " 'CAACCTAA',\n",
       " 'AACCTAAG',\n",
       " 'ACCTAAGA',\n",
       " 'CCTAAGAG',\n",
       " 'CTAAGAGA',\n",
       " 'TAAGAGAG',\n",
       " 'AAGAGAGA',\n",
       " 'AGAGAGAA',\n",
       " 'GAGAGAAG',\n",
       " 'AGAGAAGG',\n",
       " 'GAGAAGGG',\n",
       " 'AGAAGGGG',\n",
       " 'GAAGGGGT',\n",
       " 'AAGGGGTT',\n",
       " 'AGGGGTTT',\n",
       " 'GGGGTTTT',\n",
       " 'GGGTTTTG',\n",
       " 'GGTTTTGT',\n",
       " 'GTTTTGTG',\n",
       " 'TTTTGTGT',\n",
       " 'TTTGTGTT',\n",
       " 'TTGTGTTA',\n",
       " 'TGTGTTAG',\n",
       " 'GTGTTAGC',\n",
       " 'TGTTAGCA',\n",
       " 'GTTAGCAG',\n",
       " 'TTAGCAGT',\n",
       " 'TAGCAGTT',\n",
       " 'AGCAGTTT',\n",
       " 'GCAGTTTC',\n",
       " 'CAGTTTCT',\n",
       " 'AGTTTCTT',\n",
       " 'GTTTCTTC',\n",
       " 'TTTCTTCA',\n",
       " 'TTCTTCAT',\n",
       " 'TCTTCATG',\n",
       " 'CTTCATGC',\n",
       " 'TTCATGCA',\n",
       " 'TCATGCAT',\n",
       " 'CATGCATC',\n",
       " 'ATGCATCT',\n",
       " 'TGCATCTC',\n",
       " 'GCATCTCT',\n",
       " 'CATCTCTT',\n",
       " 'ATCTCTTT',\n",
       " 'TCTCTTTA',\n",
       " 'CTCTTTAC',\n",
       " 'TCTTTACA',\n",
       " 'CTTTACAA',\n",
       " 'TTTACAAG',\n",
       " 'TTACAAGA',\n",
       " 'TACAAGAA',\n",
       " 'ACAAGAAT',\n",
       " 'CAAGAATT',\n",
       " 'AAGAATTA',\n",
       " 'AGAATTAC',\n",
       " 'GAATTACA',\n",
       " 'AATTACAG',\n",
       " 'ATTACAGG',\n",
       " 'TTACAGGA',\n",
       " 'TACAGGAG',\n",
       " 'ACAGGAGC',\n",
       " 'CAGGAGCC',\n",
       " 'AGGAGCCA',\n",
       " 'GGAGCCAA',\n",
       " 'GAGCCAAA',\n",
       " 'AGCCAAAC',\n",
       " 'GCCAAACA',\n",
       " 'CCAAACAC',\n",
       " 'CAAACACT',\n",
       " 'AAACACTC',\n",
       " 'AACACTCG',\n",
       " 'ACACTCGC',\n",
       " 'CACTCGCT',\n",
       " 'ACTCGCTG',\n",
       " 'CTCGCTGT',\n",
       " 'TCGCTGTC',\n",
       " 'CGCTGTCA',\n",
       " 'GCTGTCAT',\n",
       " 'CTGTCATG',\n",
       " 'TGTCATGG',\n",
       " 'GTCATGGT',\n",
       " 'TCATGGTA',\n",
       " 'CATGGTAT',\n",
       " 'ATGGTATC',\n",
       " 'TGGTATCG',\n",
       " 'GGTATCGA',\n",
       " 'GTATCGAC',\n",
       " 'TATCGACA',\n",
       " 'ATCGACAT',\n",
       " 'TCGACATA',\n",
       " 'CGACATAT',\n",
       " 'GACATATC',\n",
       " 'ACATATCG',\n",
       " 'CATATCGC',\n",
       " 'ATATCGCT',\n",
       " 'ATCGCAAA',\n",
       " 'TCGCAAAC',\n",
       " 'CGCAAACC',\n",
       " 'GCAAACCG',\n",
       " 'CAAACCGA',\n",
       " 'AAACCGAC',\n",
       " 'AACCGACT',\n",
       " 'ACCGACTG',\n",
       " 'CCGACTGT',\n",
       " 'CGACTGTC',\n",
       " 'GACTGTCG',\n",
       " 'ACTGTCGG',\n",
       " 'CTGTCGGA',\n",
       " 'TGTCGGAC',\n",
       " 'GTCGGACT',\n",
       " 'TCGGACTC',\n",
       " 'CGGACTCT',\n",
       " 'GGACTCTT',\n",
       " 'GACTCTTT',\n",
       " 'ACTCTTTC',\n",
       " 'CTCTTTCA',\n",
       " 'TCTTTCAT',\n",
       " 'CTTTCATG',\n",
       " 'TTTCATGA',\n",
       " 'TTCATGAG',\n",
       " 'TCATGAGC',\n",
       " 'CATGAGCA',\n",
       " 'ATGAGCAA',\n",
       " 'TGAGCAAA',\n",
       " 'GAGCAAAA',\n",
       " 'AGCAAAAA',\n",
       " 'GCAAAAAA',\n",
       " 'CAAAAAAA',\n",
       " 'AAAAAAAG',\n",
       " 'AAAAAAGT',\n",
       " 'AAAAAGTG',\n",
       " 'AAAAGTGG',\n",
       " 'AAAGTGGG',\n",
       " 'AAGTGGGA',\n",
       " 'AGTGGGAG',\n",
       " 'GTGGGAGT',\n",
       " 'TGGGAGTA',\n",
       " 'GGGAGTAT',\n",
       " 'GGAGTATG',\n",
       " 'GAGTATGG',\n",
       " 'AGTATGGT',\n",
       " 'GTATGGTG',\n",
       " 'TATGGTGC',\n",
       " 'ATGGTGCA',\n",
       " 'TGGTGCAC',\n",
       " 'GGTGCACA',\n",
       " 'GTGCACAT',\n",
       " 'TGCACATC',\n",
       " 'GCACATCC',\n",
       " 'CACATCCG',\n",
       " 'ACATCCGC',\n",
       " 'CATCCGCT',\n",
       " 'ATCCGCTA',\n",
       " 'TCCGCTAT',\n",
       " 'CCGCTATC',\n",
       " 'CTATCGCT',\n",
       " 'TATCGCTG',\n",
       " 'ATCGCTGC',\n",
       " 'TCGCTGCC',\n",
       " 'CGCTGCCC',\n",
       " 'GCTGCCCG',\n",
       " 'CTGCCCGG',\n",
       " 'TGCCCGGA',\n",
       " 'GCCCGGAG',\n",
       " 'CCCGGAGG',\n",
       " 'CCGGAGGC',\n",
       " 'CGGAGGCG',\n",
       " 'GGAGGCGC',\n",
       " 'GAGGCGCT',\n",
       " 'AGGCGCTA',\n",
       " 'GGCGCTAT',\n",
       " 'GCGCTATC',\n",
       " 'CGCTATCG',\n",
       " 'TATCGCTA',\n",
       " 'ATCGCTAC',\n",
       " 'TCGCTACT',\n",
       " 'CGCTACTG',\n",
       " 'GCTACTGG',\n",
       " 'CTACTGGT',\n",
       " 'TACTGGTG',\n",
       " 'ACTGGTGC',\n",
       " 'CTGGTGCC',\n",
       " 'TGGTGCCG',\n",
       " 'GGTGCCGC',\n",
       " 'GTGCCGCC',\n",
       " 'TGCCGCCC',\n",
       " 'GCCGCCCT',\n",
       " 'CCGCCCTT',\n",
       " 'CGCCCTTC',\n",
       " 'GCCCTTCG',\n",
       " 'CCCTTCGA',\n",
       " 'CCTTCGAT',\n",
       " 'CTTCGATG',\n",
       " 'TTCGATGC',\n",
       " 'TCGATGCA',\n",
       " 'CGATGCAA',\n",
       " 'GATGCAAT',\n",
       " 'ATGCAATG',\n",
       " 'TGCAATGT',\n",
       " 'GCAATGTT']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print assembled sequence\n",
    "print(\"Sequence of k mers\")\n",
    "path_nodes.reverse()\n",
    "path.reverse()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blank-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main assembly algorithm\n",
    "\n",
    "def assemble_sequence(path):\n",
    "    assembled_sequence = path[0]\n",
    "    for i in range(len(path)):\n",
    "        assembled_sequence += path[i][-1]\n",
    "    return assembled_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "expired-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TACGCCAAAATAGCAATGCGCAGGATAACAACTTATGTACTACATGTTGTTTCTCGTGCCCGCCAATGTCGAGAGATTTGTGCTATCGCAACCTAAGAGAGAAGGGGTTTTGTGTTAGCAGTTTCTTCATGCATCTCTTTACAAGAATTACAGGAGCCAAACACTCGCTGTCATGGTATCGACATATCGCTACCGACTGTCGGACTCTTTCATGAGCAAAAAAAGTGGGAGTATGGTGCACATCCGCTATCTGCCCGGAGGCGCTATCGACTGGTGCCGCCCTTCGATGCAATGTT\n"
     ]
    }
   ],
   "source": [
    "# Output assembled sequence\n",
    "\n",
    "assembled_seq = assemble_sequence(path)\n",
    "print(assembled_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-questionnaire",
   "metadata": {},
   "source": [
    "## Question 2 - Sequencing SARS-CoV-2 virus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-biography",
   "metadata": {},
   "source": [
    "Let's move on from TeleTubbies to real-world organisms. Let's start small- with a variant of the SARS-CoV-2 virus. You're given reads from <i>actual</i> genome sequencing runs in the SARS-CoV2.fastq file provided.\n",
    "\n",
    "Repeat Question 1.3 on this data. You can re-use your implementation and simply run it on the new data. Print out your reconstructed sequence to a file \"output.txt\". For this part, we will still assume that all the reads are error-free. Set $k=25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "legitimate-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sequence reads\n",
    "sequence_reads_covid, qualities_covid = utils.read_fastq('SARS-CoV2.fastq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "formal-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read reads into graph\n",
    "nodes_covid, edges_covid, matrix_covid, outdegrees_covid, indegrees_covid = build_graph(sequence_reads_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c69fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_covid, end_covid = endpoints(outdegrees_covid, indegrees_covid, nodes_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c423df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "path_covid, path_nodes_covid = dfs_wrap(matrix_covid, start_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call main assembly algorithm\n",
    "assmebled_covid_seq = assemble_sequence(path_covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-stretch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write assembled sequence to file\n",
    "\n",
    "with open(\"covid_overlap.txt\", \"w\") as f:\n",
    "    f.write(assmebled_covid_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-month",
   "metadata": {},
   "source": [
    "# Question 3- Error-Aware Assembly (Extra Credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-absorption",
   "metadata": {},
   "source": [
    "In the parts above, we assumed error-free reads while assembling $k$-mers. As much as we'd like that, actual reads can (and do) have errors, captured by their Phred scores. For this question, you're given raw, actual reads from sequencing runs (download reads here: https://sra-pub-sars-cov2.s3.amazonaws.com/sra-src/SRR11528307/ABS2-LN-R1_cleaned_paired.fastq.gz).  Given these reads and their Phred33 scores, can you assemble the genome?\n",
    "\n",
    "<b>Print out your assembled sequence, along with a brief explanation of how your algorithm works</b>\n",
    "\n",
    "This is an open-ended question. You are free to use any approach to deal with the issue. Make sure you provide your code, along with any assumptions you may have, in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-manual",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-delay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "84472160e2b844a33d80e075be3132bfe2565675498812d4ae3271c87f1aca37"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
